# History and Philosophy of AI
## 9/25/14

Development of science is not the rational process that most believe it is

## A Long Time Ago, Far Far Away
In 1956, at Darmouth, several researchers got together to discuess the hypothesis that
- You can use logic and computers to prove mathematical theorems
    - Called logical inference
- Insight: You had to be smart to do logic, if we could get computers to do it, then they will become
smart!
- Saw logical inference as a path to Artificial Intelligence
    - Would ultimately become known as Symbolic Systems approach
    - Define rules and symbols and apply them to come to conclusions
Researchers put most of their efforts into finding efficient methods of applying rules
As long as they focused on problems that did not require too much practical knowledge

Engineers eventually lost interest in symbolic systems approach, started looking for a better approach

## Machine Learning
- Eventually, researchers settled upon the approach of collecting large amounts of data and using it to 'teach' machines
- Most machine learning engineers focused more on solving problems
    - Embraced new tools and applied them
- Research began to shift away from Symbolic Systems and towards Machine Learning
    - Mathematicians and Logicians (sp?) started to be left behind

## Khuns Paradigm Shifts
The Khun Cycle:
1.  Normal Science
2.  Model Drift
3.  Model Crisis
4.  Model Revolution
5.  Paradigm Shift

Shift in scientific research is not driven by scientific forces per say, but more on intangible forces such as
human favor

## Operating System Wars
Thomas Edison:
- Advocated Direct Current as means of delivering electricity

Westinghouse:
- Advocated use of alternating current
- Westinghouse eventually won out, but today we remember Thomas Edison... go figure

## Fred Terman
Interested in the question: 'What else could we do with electricity?'
- Shifted to research in electrotechnics \- or what we consider electronics today

In 1937, 21 year old Claude Shannon wrote a thesis that changed the field of electronics.
- His insight was that boolean algebra and binary arithmetic can be used to model the behavior of
electronic circuits
    - Basically means that if the power is flowing, we have a 1
    - If the power is not flowing, we have a 0

## Bright Ideas Dim Over Time
Things we consider obvious today once were not so obvious... required someone finding a key insight to open our eyes
to the novel ideas

## Back to Shannons insight...
Thanks to his work, people could now MODEL circuits before they were built, leading to the design and creation
of more complex circuits
- This included the ability to make complex calculation

First customer was the Department of Defense (Called the War Department back then...)
- They needed to calculate ballistic tables for weaponry, computing trajectories
- Used to be a painful process done by hand
- But with machine calculators, could be done quickly and less painfully!
    - Interating note... Human calculators were all women
    - Women were regarded as better suited to that type of work, because they were believed to be more like machines than men.
    - Operating the new machines was then regarded as work for women

## Post-WWII
There was a tremendous amount of investment in electronic products, and people needed to find 
comercial uses for them
- By the 1950s, companies such as IBM saw a market for computers as productivity aids to replace clerks
in offices

Human and Machine Intelligence
- If computers could crunch numbers and data, why couldnt they think?
- Back to the summer of 1956..
    - Conference hosted to discuss machine intelligence
    - Founding Fathers of AI
        - J. McCarthy
        - M Minsky
        - N Rochester
        - C.E. Shannon
    - Wanted to figure out how to make machines understand language, improve themselves, etc.
    - "We think that a significant advance in this field can be achieved if a group of scientists work on this together over the course of a summer"
        - Talk about overblown expectations!
- McCarthy believed that logical inference was the key to creating simulated intelligence

## The Physical Symbol Systems Hypothesis
A physical symbol system has the necessary and sufficient means for general intelligent action
    - Alan Newell and Herbert Simon, 1976
- Can have an arbitrary set of symbols and rules, make it up as you go along
- Syntax (symbols and rules) is sufficient for intelligence

## Semantics
- Structure of a symbol system means something in the context of the real world..
- Represent that truth through its structure
- Need to take symbols and assign them meaning to something in the real world
    - If you think about it, its amazing that mathematics even means anything

Symbolic Systems tend to work through deduction 
- Symbolic representation leads to insight in the real world
But inductive systems works the opposite direction
- Insights from the real world lead to creation of symbols to represent them

## Machine Learning
Can be broken down into two steps
1. Learn
- Induce a representation of the input data from some problem domain
2. Apply

Applied with many common techniques, but the most common are using good old statistics and neural networks

The structure of machine learning programs can be reasonably characterized as programs that develop their own language
- But machine learning programmers generally do not think they are working with symbols
    - But their programs ARE!
    - Their programs do not need words, they just need to be able to reference things internally...
    - Symbols they use generally represent concepts that are not easy to map to human language
        - We are not equipped to discuss the internal language of machine learning systems
    - This is what makes AI so freaking awesome and a little bit scary!

It took human beings hundreds of centuries to develop our symbol systems, but it can take machine learning systems a matter of hours
- They can learn faster than we can
- Can develop deeper insights than we can
- Operate in speeds that far exceed our own
- If we can reproduce the underlying algorithms of our own intelligence and reproduce them in machines, they will be able
to far surpass us

## Jerry Kaplan Conclusion: Both symbolic systems and machine learning approaches are going to have rolls in the future of AI
- They are different tools for different tasks

| Symbolic Systems | Machine Learning |
| ---------------- | ---------------- |
| Efficient | Flexible |
| Deductive | Inductive | 
| Limited, well-defined domains | noisy, real-world domains |
| Handcrafted Input | Requires large dataasets |
| Clear Conclusions | Tentative Conclusions |
| Not Easily Scalable | Scales relative to input |
| Process driven | Data driven |

## Technology Drives Science 
The problems we work on, and the tools we develop, are driven by our chosen technologies

# Summary
- Science proceeds unscientifically
- Symbolic Systems and Machine Learning are two sides of the same coin (deduction vs induction)
- Technology advances drove the transition from the former to the latter
